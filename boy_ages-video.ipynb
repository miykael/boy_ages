{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aging son\n",
    "\n",
    "This notebook can be used to average images of an aging kid, similar to what was done for miykael's [Noah ages](https://github.com/miykael/noah_ages) project. In short, we use the [dlib](http://dlib.net/) toolbox to detect, extract and align faces from all images. The process to do so is a 2-step process:\n",
    "\n",
    "1. We use `hog_detector` detector to find the faces in all images. This detector is 'ok-ish' but runs very quickly.\n",
    "2. For all images where it wasn't possible to detect a face, we use the `cnn_face_detection_model_v1` routine. This routine is slower but more accurate.\n",
    "\n",
    "Dlib's face detection is usually used to extract small 'chips'/patches of pixels that only contain the face. In this case however we decided to keep the full image, but just profit from dlib's routine of aligning the faces according to the 5 landmarks (two eyes, nose and two corners of the mouth). During this procedure, images can also be rescaled to any resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "\n",
    "But before we can start, let's make sure that all relevant packages are installed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -qU dlib opencv-python tqdm ipywidgets scikit-learn scikit-image tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from matplotlib import patches\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import dlib\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define relevant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_identifier = 'PXL_*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder for aligned images\n",
    "out_dir = Path('imgs_aligned')\n",
    "if not out_dir.exists():\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of face chip\n",
    "max_size = 4320\n",
    "downsample = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load content"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get images files from google drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect filenames\n",
    "path_to_img_folder = '/Users/username/Documents/photo_folder/'\n",
    "path_imgs = Path(path_to_img_folder)\n",
    "filenames = sorted(path_imgs.glob(file_identifier))\n",
    "n_files = len(filenames)\n",
    "print(f\"{n_files} images were found, representing {n_files / 365.25:.2f} years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct and align images with `skimage` and `dlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dlib models for face recognition\n",
    "shape_predictor = dlib.shape_predictor('dlib/shape_predictor_5_face_landmarks.dat') # Faces landmarks (points)\n",
    "\n",
    "# Define which face detector to use\n",
    "hog_detector = dlib.get_frontal_face_detector()\n",
    "cnn_detector = dlib.cnn_face_detection_model_v1('dlib/mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through with hog_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN is more advanced but takes longer; hog misses ~100 faces in total\n",
    "face_detector = hog_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all images\n",
    "for f in tqdm(filenames):\n",
    "\n",
    "    # Specify output filename \n",
    "    out_filename = out_dir / f.name\n",
    "    \n",
    "    # Skip image processing if output file was already created\n",
    "    if out_filename.exists():\n",
    "        continue\n",
    "\n",
    "    # Load image\n",
    "    im = io.imread(f)[..., :3]\n",
    "\n",
    "    # Get information about image size\n",
    "    w, h = im.shape[:2]\n",
    "    w_offset = (max_size-w)//2\n",
    "    h_offset = (max_size-h)//2\n",
    "\n",
    "    # Center image in a canvas\n",
    "    canvas = np.zeros((max_size, max_size, 3)).astype('uint8')\n",
    "    canvas[w_offset:w_offset+w, h_offset:h_offset+h, :] = im\n",
    "    \n",
    "    # Detect faces and align image\n",
    "    rectangles = [x if isinstance(x, dlib.rectangle)\n",
    "                  else x.rect for x in face_detector(canvas, 1)]\n",
    "    if len(rectangles):\n",
    "        landmarks = [shape_predictor(canvas, r) for r in rectangles]\n",
    "        face_chips = [dlib.get_face_chip(\n",
    "            canvas, l, size=max_size//downsample, padding=1) for l in landmarks]\n",
    "\n",
    "        # Save aligned image\n",
    "        io.imsave(out_filename, face_chips[0])\n",
    "\n",
    "    else:\n",
    "        print('No face found in', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Manually delete the images in the `imgs_aligned` folder where the face detection didn't work correctly. The code below will then try to detect the face with a more advanced algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through issue images with cnn_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN is more advanced but takes much longer\n",
    "face_detector = cnn_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all images\n",
    "for f in tqdm(filenames):\n",
    "\n",
    "    # Specify output filename \n",
    "    out_filename = out_dir / f.name\n",
    "    \n",
    "    # Skip image processing if output file was already created\n",
    "    if out_filename.exists():\n",
    "        continue\n",
    "\n",
    "    # Load image\n",
    "    im = io.imread(f)[..., :3]\n",
    "\n",
    "    # Get information about image size\n",
    "    w, h = im.shape[:2]\n",
    "    w_offset = (max_size-w)//2\n",
    "    h_offset = (max_size-h)//2\n",
    "\n",
    "    # Center image in a canvas\n",
    "    canvas = np.zeros((max_size, max_size, 3)).astype('uint8')\n",
    "    canvas[w_offset:w_offset+w, h_offset:h_offset+h, :] = im\n",
    "    \n",
    "    # Detect faces and align image\n",
    "    rectangles = [x if isinstance(x, dlib.rectangle)\n",
    "                  else x.rect for x in face_detector(canvas, 1)]\n",
    "    if len(rectangles):\n",
    "        landmarks = [shape_predictor(canvas, r) for r in rectangles]\n",
    "        face_chips = [dlib.get_face_chip(\n",
    "            canvas, l, size=max_size//downsample, padding=1) for l in landmarks]\n",
    "\n",
    "        # Save aligned image\n",
    "        io.imsave(out_filename, face_chips[0])\n",
    "\n",
    "    else:\n",
    "        print('Still no faces found in', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images\n",
    "print(f\"Number of original images: {len(filenames)}\")\n",
    "imgs_aligned = sorted(out_dir.glob(file_identifier))\n",
    "print(f\"Number of aligned images:  {len(imgs_aligned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: For those faces where the alignment didn't work at all, or not good enough, you will need to perform a manual alignment. The next section in this notebook will create an average image that should help to align the missing/misaligned images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all images\n",
    "imgs = np.array([io.imread(path_align)[..., :3] for path_align in tqdm(imgs_aligned)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create average image that can be used for alignment\n",
    "img_avg = np.mean(imgs, axis=0) / 255.\n",
    "img_median = np.median(imgs, axis=0) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average images\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axs[0].imshow(img_avg)\n",
    "axs[1].imshow(img_median)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store average images to file\n",
    "plt.imsave('img_01_avg.png', img_avg)\n",
    "plt.imsave('img_01_median.png', img_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of certain size of first x images\n",
    "grid_size = np.array([5, 3])\n",
    "zoom_factor = 4\n",
    "grid_points = np.prod(grid_size)\n",
    "imgs_averages = np.array_split(imgs, grid_points)\n",
    "fig, axes = plt.subplots(\n",
    "    grid_size[1], grid_size[0], figsize=grid_size * zoom_factor, facecolor=(0, 0, 0)\n",
    ")\n",
    "for i, ax in zip(np.arange(grid_points), axes.flatten()):\n",
    "    ax.imshow(imgs_averages[i].mean(0).astype(\"int\"))\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('img_02_mosaic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video 1: No averaging\n",
    "\n",
    "Note, get the font for the text in the image from [here](https://fonts.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify frames per second\n",
    "fps = 30\n",
    "\n",
    "# Extract number of images\n",
    "N_total = len(imgs_aligned)\n",
    "\n",
    "print('Video length: %.2f seconds.' % (N_total/fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary folder to store images to disk\n",
    "tmp_dir = Path('tmp_video_imgs')\n",
    "if not tmp_dir.exists():\n",
    "    tmp_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect images with text\n",
    "imgs_txt = []\n",
    "\n",
    "# Loop through all images and add text\n",
    "for idx in tqdm(np.arange(len(imgs_aligned))):\n",
    "\n",
    "    # Load aligned image\n",
    "    im = io.imread(imgs_aligned[idx])\n",
    "\n",
    "    # Collect year specific information\n",
    "    n_year = idx / 365.25\n",
    "    n_month = n_year * 12 % 12\n",
    "    n_days = idx % 31\n",
    "    n_year = int(np.floor(n_year))\n",
    "    n_month = int(np.floor(n_month))\n",
    "    n_days = int(np.floor(n_days))\n",
    "    title_txt = f\"{n_year:02d} years, {n_month+1:02d} months, {n_days+1:03d} days\"\n",
    "\n",
    "    # Establish out_filename\n",
    "    out_filename = tmp_dir / f'{idx+1:04d}.jpg'\n",
    "\n",
    "    # Add text to output filename\n",
    "    img_txt = Image.fromarray(im)\n",
    "    draw = ImageDraw.Draw(img_txt)\n",
    "    width = max_size//downsample\n",
    "    font = ImageFont.truetype(\"Roboto/Roboto-Light.ttf\", int(width*.06))\n",
    "    draw.text((width*0.1, width*0.9), title_txt, (255, 255, 255), font=font)\n",
    "\n",
    "    # Store image to file\n",
    "    io.imsave(out_filename, np.array(img_txt))\n",
    "    \n",
    "    # Add image with text to list\n",
    "    imgs_txt.append(np.array(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either code (the onze that works) to create the video\n",
    "!cat tmp_video_imgs/*jpg | ffmpeg -y -f image2pipe -r $fps -vcodec mjpeg -i - -vcodec libx264 video_01_aligned.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all temporary files\n",
    "for p in sorted(tmp_dir.glob('*jpg')):\n",
    "    p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create averaged images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images to smooth at once\n",
    "smooth = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many days to jump at every image\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start indeces for images\n",
    "ids = [i*step_size for i in range((N_total+smooth)//step_size+1)]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep track what was already loaded\n",
    "already_loaded = []\n",
    "idx_range = np.arange(len(imgs_txt))\n",
    "\n",
    "for i in tqdm(ids):\n",
    "    \n",
    "    # Collect indeces of images\n",
    "    imgs_idx = np.arange(np.clip(i-smooth, 0, N_total-1), np.clip(i, 0, N_total-1)+1)\n",
    "\n",
    "    # Collect images relevant for the group\n",
    "    group_names = idx_range[imgs_idx]\n",
    "    \n",
    "    # Detect which one is new to load\n",
    "    new_to_load = np.setdiff1d(group_names, already_loaded)\n",
    "    \n",
    "    if len(new_to_load)==0:\n",
    "        pass\n",
    "    elif i==0:\n",
    "        imgs_group = np.array([imgs_txt[fdx] for fdx in new_to_load])\n",
    "    else:\n",
    "        img_new = np.array([imgs_txt[fdx] for fdx in new_to_load])\n",
    "        imgs_group = np.vstack((imgs_group, img_new))\n",
    "        \n",
    "    # Cut imgs_group to write size\n",
    "    n_offset = (i - N_total)\n",
    "    if n_offset <= 0:\n",
    "        n_offset = 0\n",
    "    elif n_offset%2==0:\n",
    "        n_offset -= 1\n",
    "    imgs_group = imgs_group[-smooth+n_offset:]\n",
    "    \n",
    "    # Create composition image\n",
    "    img_comp_mean = np.mean(imgs_group, axis=0).astype('uint8')\n",
    "    img_comp_median = np.median(imgs_group, axis=0).astype('uint8')\n",
    "    \n",
    "    # Create out_filename\n",
    "    out_filename_mean = tmp_dir / f'{i+1:04d}_mean.jpg'\n",
    "    out_filename_median = tmp_dir / f'{i+1:04d}_median.jpg'\n",
    "    \n",
    "    # Save composition image\n",
    "    io.imsave(out_filename_mean, img_comp_mean.astype('uint8'))\n",
    "    io.imsave(out_filename_median, img_comp_median.astype('uint8'))\n",
    "\n",
    "    # Keep track of what has already been loaded\n",
    "    already_loaded = group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either code (the one that works) to create the video\n",
    "!cat tmp_video_imgs/*mean.jpg | ffmpeg -y -f image2pipe -r $fps -vcodec mjpeg -i - -vcodec libx264 video_02_smoothed_mean_X-days.mp4\n",
    "!cat tmp_video_imgs/*median.jpg | ffmpeg -y -f image2pipe -r $fps -vcodec mjpeg -i - -vcodec libx264 video_02_smoothed_median_X-days.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all temporary files\n",
    "for p in sorted(tmp_dir.glob('*jpg')):\n",
    "    p.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
